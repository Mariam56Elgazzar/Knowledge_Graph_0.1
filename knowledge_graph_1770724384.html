<html>
    <head>
        <meta charset="utf-8">
        
            <script src="lib/bindings/utils.js"></script>
            <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/dist/vis-network.min.css" integrity="sha512-WgxfT5LWjfszlPHXRmBWHkV2eceiWTOBvrKCNbdgDYTHrT2AeLCGbF4sZlZw3UMN3WtL0tGUoIAKsu8mllg/XA==" crossorigin="anonymous" referrerpolicy="no-referrer" />
            <script src="https://cdnjs.cloudflare.com/ajax/libs/vis-network/9.1.2/dist/vis-network.min.js" integrity="sha512-LnvoEWDFrqGHlHmDD2101OrLcbsfkrzoSpvtSQtxK3RMnRV0eOkhhBN2dXHKRrUU8p2DGRTk35n4O8nWSVe1mQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
            
        
<center>
<h1></h1>
</center>

<!-- <link rel="stylesheet" href="../node_modules/vis/dist/vis.min.css" type="text/css" />
<script type="text/javascript" src="../node_modules/vis/dist/vis.js"> </script>-->
        <link
          href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/css/bootstrap.min.css"
          rel="stylesheet"
          integrity="sha384-eOJMYsd53ii+scO/bJGFsiCZc+5NDVN2yr8+0RDqr0Ql0h+rP48ckxlpbzKgwra6"
          crossorigin="anonymous"
        />
        <script
          src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta3/dist/js/bootstrap.bundle.min.js"
          integrity="sha384-JEW9xMcG8R+pH31jmWH6WWP0WintQrMb4s7ZOdauHnUtxwoG2vI5DkLtS3qm9Ekf"
          crossorigin="anonymous"
        ></script>


        <center>
          <h1></h1>
        </center>
        <style type="text/css">

             #mynetwork {
                 width: 100%;
                 height: 900px;
                 background-color: #ffffff;
                 border: 1px solid lightgray;
                 position: relative;
                 float: left;
             }

             
             #loadingBar {
                 position:absolute;
                 top:0px;
                 left:0px;
                 width: 100%;
                 height: 900px;
                 background-color:rgba(200,200,200,0.8);
                 -webkit-transition: all 0.5s ease;
                 -moz-transition: all 0.5s ease;
                 -ms-transition: all 0.5s ease;
                 -o-transition: all 0.5s ease;
                 transition: all 0.5s ease;
                 opacity:1;
             }

             #bar {
                 position:absolute;
                 top:0px;
                 left:0px;
                 width:20px;
                 height:20px;
                 margin:auto auto auto auto;
                 border-radius:11px;
                 border:2px solid rgba(30,30,30,0.05);
                 background: rgb(0, 173, 246); /* Old browsers */
                 box-shadow: 2px 0px 4px rgba(0,0,0,0.4);
             }

             #border {
                 position:absolute;
                 top:10px;
                 left:10px;
                 width:500px;
                 height:23px;
                 margin:auto auto auto auto;
                 box-shadow: 0px 0px 4px rgba(0,0,0,0.2);
                 border-radius:10px;
             }

             #text {
                 position:absolute;
                 top:8px;
                 left:530px;
                 width:30px;
                 height:50px;
                 margin:auto auto auto auto;
                 font-size:22px;
                 color: #000000;
             }

             div.outerBorder {
                 position:relative;
                 top:400px;
                 width:600px;
                 height:44px;
                 margin:auto auto auto auto;
                 border:8px solid rgba(0,0,0,0.1);
                 background: rgb(252,252,252); /* Old browsers */
                 background: -moz-linear-gradient(top,  rgba(252,252,252,1) 0%, rgba(237,237,237,1) 100%); /* FF3.6+ */
                 background: -webkit-gradient(linear, left top, left bottom, color-stop(0%,rgba(252,252,252,1)), color-stop(100%,rgba(237,237,237,1))); /* Chrome,Safari4+ */
                 background: -webkit-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* Chrome10+,Safari5.1+ */
                 background: -o-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* Opera 11.10+ */
                 background: -ms-linear-gradient(top,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* IE10+ */
                 background: linear-gradient(to bottom,  rgba(252,252,252,1) 0%,rgba(237,237,237,1) 100%); /* W3C */
                 filter: progid:DXImageTransform.Microsoft.gradient( startColorstr='#fcfcfc', endColorstr='#ededed',GradientType=0 ); /* IE6-9 */
                 border-radius:72px;
                 box-shadow: 0px 0px 10px rgba(0,0,0,0.2);
             }
             

             

             
        </style>
    </head>


    <body>
        <div class="card" style="width: 100%">
            
            
            <div id="mynetwork" class="card-body"></div>
        </div>

        
            <div id="loadingBar">
              <div class="outerBorder">
                <div id="text">0%</div>
                <div id="border">
                  <div id="bar"></div>
                </div>
              </div>
            </div>
        
        

        <script type="text/javascript">

              // initialize global variables.
              var edges;
              var nodes;
              var allNodes;
              var allEdges;
              var nodeColors;
              var originalNodes;
              var network;
              var container;
              var options, data;
              var filter = {
                  item : '',
                  property : '',
                  value : []
              };

              

              

              // This method is responsible for drawing the graph, returns the drawn network
              function drawGraph() {
                  var container = document.getElementById('mynetwork');

                  

                  // parsing and collecting nodes and edges from the python
                  nodes = new vis.DataSet([{"color": "#b9d9ea", "font": {"color": "#222"}, "id": "BERT", "label": "BERT", "shape": "dot", "title": "Model"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "CIFAR-10", "label": "CIFAR-10", "shape": "dot", "title": "Dataset"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "BLEU", "label": "BLEU", "shape": "dot", "title": "Metric"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "LoRA", "label": "LoRA", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Transformer Architecture", "label": "Transformer Architecture", "shape": "dot", "title": "Model"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "WMT 2014 English-German", "label": "WMT 2014 English-German", "shape": "dot", "title": "Dataset"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "WMT 2014 English-French", "label": "WMT 2014 English-French", "shape": "dot", "title": "Dataset"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Adam", "label": "Adam", "shape": "dot", "title": "Optimizer"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "ByteNet", "label": "ByteNet", "shape": "dot", "title": "Model"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Deep-Att + PosUnk", "label": "Deep-Att + PosUnk", "shape": "dot", "title": "Model"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "GNMT + RL", "label": "GNMT + RL", "shape": "dot", "title": "Model"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "ConvS2S", "label": "ConvS2S", "shape": "dot", "title": "Model"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "MoE", "label": "MoE", "shape": "dot", "title": "Model"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Residual Dropout", "label": "Residual Dropout", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Label Smoothing", "label": "Label Smoothing", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "P100", "label": "P100", "shape": "dot", "title": "System"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "NVIDIA", "label": "NVIDIA", "shape": "dot", "title": "Organization"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "WMT 2014", "label": "WMT 2014", "shape": "dot", "title": "Benchmark"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "English-to-German", "label": "English-to-German", "shape": "dot", "title": "Task"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "English-to-French", "label": "English-to-French", "shape": "dot", "title": "Task"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Machine Translation", "label": "Machine Translation", "shape": "dot", "title": "Task"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Beam Search", "label": "Beam Search", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Length Penalty", "label": "Length Penalty", "shape": "dot", "title": "Hyperparameter"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Dropout", "label": "Dropout", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Adam Optimizer", "label": "Adam Optimizer", "shape": "dot", "title": "Optimizer"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Byte-Pair Encoding", "label": "Byte-Pair Encoding", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Word-Piece Vocabulary", "label": "Word-Piece Vocabulary", "shape": "dot", "title": "Dataset"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Self-Attention", "label": "Self-Attention", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Point-Wise Feed-Forward Layer", "label": "Point-Wise Feed-Forward Layer", "shape": "dot", "title": "Component"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Convolutional Layers", "label": "Convolutional Layers", "shape": "dot", "title": "Component"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Recurrent Layers", "label": "Recurrent Layers", "shape": "dot", "title": "Component"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Separable Convolutions", "label": "Separable Convolutions", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Residual Connection", "label": "Residual Connection", "shape": "dot", "title": "Component"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Encoder-Decoder Architecture", "label": "Encoder-Decoder Architecture", "shape": "dot", "title": "Model"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Transformer Architecture (base model)", "label": "Transformer Architecture (base model)", "shape": "dot", "title": "Model"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Transformer Architecture (big)", "label": "Transformer Architecture (big)", "shape": "dot", "title": "Model"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "WMT 2014 English-to-German", "label": "WMT 2014 English-to-German", "shape": "dot", "title": "Task"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "WMT 2014 English-to-French", "label": "WMT 2014 English-to-French", "shape": "dot", "title": "Task"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "K80", "label": "K80", "shape": "dot", "title": "Component"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "K40", "label": "K40", "shape": "dot", "title": "Component"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "M40", "label": "M40", "shape": "dot", "title": "Component"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Table 2", "label": "Table 2", "shape": "dot", "title": "Publication"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Table 3", "label": "Table 3", "shape": "dot", "title": "Publication"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Wall Street Journal", "label": "Wall Street Journal", "shape": "dot", "title": "Dataset"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Penn Treebank", "label": "Penn Treebank", "shape": "dot", "title": "Dataset"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "BerkleyParser", "label": "BerkleyParser", "shape": "dot", "title": "Dataset"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "newstest2013", "label": "newstest2013", "shape": "dot", "title": "Dataset"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "newstest2014", "label": "newstest2014", "shape": "dot", "title": "Dataset"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Google Brain", "label": "Google Brain", "shape": "dot", "title": "Organization"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "NIPS 2017", "label": "NIPS 2017", "shape": "dot", "title": "Publication"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "arXiv", "label": "arXiv", "shape": "dot", "title": "Publication"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Attention Is All You Need", "label": "Attention Is All You Need", "shape": "dot", "title": "Publication"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Recurrent Neural Networks", "label": "Recurrent Neural Networks", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Long Short-Term Memory", "label": "Long Short-Term Memory", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Gated Recurrent Neural Networks", "label": "Gated Recurrent Neural Networks", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Sequence Transduction", "label": "Sequence Transduction", "shape": "dot", "title": "Task"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "English Constituency Parsing", "label": "English Constituency Parsing", "shape": "dot", "title": "Task"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Multi-Head Attention", "label": "Multi-Head Attention", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Scaled Dot-Product Attention", "label": "Scaled Dot-Product Attention", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Position Representation", "label": "Position Representation", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Tensor2Tensor", "label": "Tensor2Tensor", "shape": "dot", "title": "System"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Extended Neural GPU", "label": "Extended Neural GPU", "shape": "dot", "title": "Model"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "P100 GPUs", "label": "P100 GPUs", "shape": "dot", "title": "System"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Google", "label": "Google", "shape": "dot", "title": "Organization"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "University of Toronto", "label": "University of Toronto", "shape": "dot", "title": "Organization"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "WMT 2014 English-to-German translation task", "label": "WMT 2014 English-to-German translation task", "shape": "dot", "title": "Task"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "WMT 2014 English-to-French translation task", "label": "WMT 2014 English-to-French translation task", "shape": "dot", "title": "Task"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Google Research", "label": "Google Research", "shape": "dot", "title": "Organization"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Ashish Vaswani", "label": "Ashish Vaswani", "shape": "dot", "title": "Author"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Noam Shazeer", "label": "Noam Shazeer", "shape": "dot", "title": "Author"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Niki Parmar", "label": "Niki Parmar", "shape": "dot", "title": "Author"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Jakob Uszkoreit", "label": "Jakob Uszkoreit", "shape": "dot", "title": "Author"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Llion Jones", "label": "Llion Jones", "shape": "dot", "title": "Author"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Aidan N. Gomez", "label": "Aidan N. Gomez", "shape": "dot", "title": "Author"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "\u0141ukasz Kaiser", "label": "\u0141ukasz Kaiser", "shape": "dot", "title": "Author"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Illia Polosukhin", "label": "Illia Polosukhin", "shape": "dot", "title": "Author"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Recurrent Neural Network", "label": "Recurrent Neural Network", "shape": "dot", "title": "Model"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Gated Recurrent Neural Network", "label": "Gated Recurrent Neural Network", "shape": "dot", "title": "Model"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "End-to-End Memory Network", "label": "End-to-End Memory Network", "shape": "dot", "title": "Model"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Point-Wise Fully Connected Layer", "label": "Point-Wise Fully Connected Layer", "shape": "dot", "title": "Component"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Layer Normalization", "label": "Layer Normalization", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Sequence Modeling", "label": "Sequence Modeling", "shape": "dot", "title": "Task"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Language Modeling", "label": "Language Modeling", "shape": "dot", "title": "Task"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Attention Mechanism", "label": "Attention Mechanism", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Recurrent Attention Mechanism", "label": "Recurrent Attention Mechanism", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Sequence-Aligned Recurrence", "label": "Sequence-Aligned Recurrence", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Additive Attention", "label": "Additive Attention", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Dot-Product Attention", "label": "Dot-Product Attention", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "LayerNorm", "label": "LayerNorm", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Position-Wise Fully Connected Feed-Forward Network", "label": "Position-Wise Fully Connected Feed-Forward Network", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Encoder", "label": "Encoder", "shape": "dot", "title": "Component"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Decoder", "label": "Decoder", "shape": "dot", "title": "Component"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Encoder Stack", "label": "Encoder Stack", "shape": "dot", "title": "Component"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Decoder Stack", "label": "Decoder Stack", "shape": "dot", "title": "Component"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Attention Function", "label": "Attention Function", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Query", "label": "Query", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Key", "label": "Key", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Value", "label": "Value", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Softmax Function", "label": "Softmax Function", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Matrix Multiplication", "label": "Matrix Multiplication", "shape": "dot", "title": "Technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Attention mechanisms", "label": "Attention mechanisms", "shape": "dot", "title": "Concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "28.4 BLEU", "label": "28.4 BLEU", "shape": "dot", "title": "Metric"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "41.8 BLEU", "label": "41.8 BLEU", "shape": "dot", "title": "Metric"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "31st Conference on Neural Information Processing Systems", "label": "31st Conference on Neural Information Processing Systems", "shape": "dot", "title": "Event"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "self-attention layer", "label": "self-attention layer", "shape": "dot", "title": "layer"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "recurrent layer", "label": "recurrent layer", "shape": "dot", "title": "layer"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "convolutional layer", "label": "convolutional layer", "shape": "dot", "title": "layer"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "computational performance", "label": "computational performance", "shape": "dot", "title": "performance"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "interpretable models", "label": "interpretable models", "shape": "dot", "title": "models"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "restricted self-attention", "label": "restricted self-attention", "shape": "dot", "title": "layer"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "model", "label": "model", "shape": "dot", "title": "model"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "sequential operations", "label": "sequential operations", "shape": "dot", "title": "operations"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "kernel width", "label": "kernel width", "shape": "dot", "title": "parameter"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "dilated convolutions", "label": "dilated convolutions", "shape": "dot", "title": "technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "WMT 2014 English-German dataset", "label": "WMT 2014 English-German dataset", "shape": "dot", "title": "dataset"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "WMT 2014 English-French dataset", "label": "WMT 2014 English-French dataset", "shape": "dot", "title": "dataset"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "sequence transduction tasks", "label": "sequence transduction tasks", "shape": "dot", "title": "task"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "position", "label": "position", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "positional encoding", "label": "positional encoding", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "sine and cosine functions", "label": "sine and cosine functions", "shape": "dot", "title": "function"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "learned positional embeddings", "label": "learned positional embeddings", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "ability to extrapolate", "label": "ability to extrapolate", "shape": "dot", "title": "ability"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "attention distribution", "label": "attention distribution", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "syntactic and semantic structure", "label": "syntactic and semantic structure", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "single-head attention", "label": "single-head attention", "shape": "dot", "title": "technique"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "multi-head(Q, K, V ) = Concat(head 1, ..., headh)W O", "label": "multi-head(Q, K, V ) = Concat(head 1, ..., headh)W O", "shape": "dot", "title": "equation"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "h = 8 parallel attention layers", "label": "h = 8 parallel attention layers", "shape": "dot", "title": "parameter"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "dk = dv = dmodel/h = 64", "label": "dk = dv = dmodel/h = 64", "shape": "dot", "title": "parameter"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "encoder-decoder attention", "label": "encoder-decoder attention", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "self-attention layers", "label": "self-attention layers", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "all of the keys, values and queries come from the same place", "label": "all of the keys, values and queries come from the same place", "shape": "dot", "title": "description"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Position-wise Feed-Forward Networks", "label": "Position-wise Feed-Forward Networks", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "fully connected feed-forward network", "label": "fully connected feed-forward network", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "two linear transformations with a ReLU activation in between", "label": "two linear transformations with a ReLU activation in between", "shape": "dot", "title": "description"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "embeddings", "label": "embeddings", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "learned embeddings", "label": "learned embeddings", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "weight matrix", "label": "weight matrix", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "recurrent and convolutional layers", "label": "recurrent and convolutional layers", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "learning long-range dependencies", "label": "learning long-range dependencies", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "positional encodings", "label": "positional encodings", "shape": "dot", "title": "concept"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "sine and cosine functions of different frequencies", "label": "sine and cosine functions of different frequencies", "shape": "dot", "title": "description"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "positional encodings have the same dimension dmodel as the embeddings", "label": "positional encodings have the same dimension dmodel as the embeddings", "shape": "dot", "title": "description"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "attention layers", "label": "attention layers", "shape": "dot", "title": "component"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "jointly attend to information from different representation subspaces at different positions", "label": "jointly attend to information from different representation subspaces at different positions", "shape": "dot", "title": "capability"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "parallel attention layers", "label": "parallel attention layers", "shape": "dot", "title": "component"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "encoder-decoder attention layers", "label": "encoder-decoder attention layers", "shape": "dot", "title": "component"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "linear transformations", "label": "linear transformations", "shape": "dot", "title": "component"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "Embeddings and Softmax", "label": "Embeddings and Softmax", "shape": "dot", "title": "component"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "dot-product attention without scaling", "label": "dot-product attention without scaling", "shape": "dot", "title": "algorithm"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "scaling factor", "label": "scaling factor", "shape": "dot", "title": "component"}, {"color": "#b9d9ea", "font": {"color": "#222"}, "id": "linear projections", "label": "linear projections", "shape": "dot", "title": "component"}]);
                  edges = new vis.DataSet([{"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "ACHIEVES", "to": "BLEU"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "EXTENDS", "to": "Residual Dropout"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "EXTENDS", "to": "Label Smoothing"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "EXTENDS", "to": "Table 2"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "EXTENDS", "to": "Table 3"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "DEPENDS_ON", "to": "P100"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "DEPENDS_ON", "to": "K80"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "DEPENDS_ON", "to": "K40"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "DEPENDS_ON", "to": "M40"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "DEPENDS_ON", "to": "Table 2"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "DEPENDS_ON", "to": "Table 3"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "EXTENDS", "to": "Wall Street Journal"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "EXTENDS", "to": "Penn Treebank"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "EXTENDS", "to": "BerkleyParser"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "EXTENDS", "to": "newstest2013"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "EXTENDS", "to": "newstest2014"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "RELATED_TO", "to": "Attention mechanisms"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "RELATED_TO", "to": "Self-Attention"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "RELATED_TO", "to": "Multi-Head Attention"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "RELATED_TO", "to": "Position Representation"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "RELATED_TO", "to": "Scaled Dot-Product Attention"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "RELATED_TO", "to": "Machine Translation"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "RELATED_TO", "to": "Sequence Transduction"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "RELATED_TO", "to": "English Constituency Parsing"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "RELATED_TO", "to": "Recurrent Neural Networks"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "RELATED_TO", "to": "Long Short-Term Memory"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "RELATED_TO", "to": "Gated Recurrent Neural Networks"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "RELATED_TO", "to": "Extended Neural GPU"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "RELATED_TO", "to": "ByteNet"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "RELATED_TO", "to": "ConvS2S"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "RELATED_TO", "to": "Tensor2Tensor"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "RELATED_TO", "to": "P100 GPUs"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "RELATED_TO", "to": "NVIDIA"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "RELATED_TO", "to": "Google"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "RELATED_TO", "to": "University of Toronto"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "RELATED_TO", "to": "Google Brain"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "RELATED_TO", "to": "Google Research"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "RELATED_TO", "to": "NIPS 2017"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "RELATED_TO", "to": "arXiv"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "RELATED_TO", "to": "Attention Is All You Need"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "PROPOSES", "to": "Ashish Vaswani"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "IMPLEMENTS", "to": "Tensor2Tensor"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "ACHIEVES", "to": "28.4 BLEU"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "ACHIEVES", "to": "41.8 BLEU"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "EXTENDS", "to": "English Constituency Parsing"}, {"arrows": "to", "color": "#97c2fc", "from": "Ashish Vaswani", "label": "CONTRIBUTES_TO", "to": "Transformer Architecture"}, {"arrows": "to", "color": "#97c2fc", "from": "Noam Shazeer", "label": "CONTRIBUTES_TO", "to": "Transformer Architecture"}, {"arrows": "to", "color": "#97c2fc", "from": "Niki Parmar", "label": "CONTRIBUTES_TO", "to": "Transformer Architecture"}, {"arrows": "to", "color": "#97c2fc", "from": "Jakob Uszkoreit", "label": "CONTRIBUTES_TO", "to": "Transformer Architecture"}, {"arrows": "to", "color": "#97c2fc", "from": "Llion Jones", "label": "CONTRIBUTES_TO", "to": "Transformer Architecture"}, {"arrows": "to", "color": "#97c2fc", "from": "\u0141ukasz Kaiser", "label": "CONTRIBUTES_TO", "to": "Transformer Architecture"}, {"arrows": "to", "color": "#97c2fc", "from": "Aidan N. Gomez", "label": "CONTRIBUTES_TO", "to": "Transformer Architecture"}, {"arrows": "to", "color": "#97c2fc", "from": "Illia Polosukhin", "label": "CONTRIBUTES_TO", "to": "Transformer Architecture"}, {"arrows": "to", "color": "#97c2fc", "from": "Google Brain", "label": "IMPLEMENTS", "to": "Transformer Architecture"}, {"arrows": "to", "color": "#97c2fc", "from": "Google Research", "label": "IMPLEMENTS", "to": "Transformer Architecture"}, {"arrows": "to", "color": "#97c2fc", "from": "University of Toronto", "label": "IMPLEMENTS", "to": "Transformer Architecture"}, {"arrows": "to", "color": "#97c2fc", "from": "Attention Is All You Need", "label": "PROPOSES", "to": "Transformer Architecture"}, {"arrows": "to", "color": "#97c2fc", "from": "Attention Is All You Need", "label": "IMPLEMENTS", "to": "Tensor2Tensor"}, {"arrows": "to", "color": "#97c2fc", "from": "Attention Is All You Need", "label": "ACHIEVES", "to": "28.4 BLEU"}, {"arrows": "to", "color": "#97c2fc", "from": "Attention Is All You Need", "label": "ACHIEVES", "to": "41.8 BLEU"}, {"arrows": "to", "color": "#97c2fc", "from": "Attention Is All You Need", "label": "EXTENDS", "to": "English Constituency Parsing"}, {"arrows": "to", "color": "#97c2fc", "from": "arXiv", "label": "PUBLISHED_IN", "to": "Attention Is All You Need"}, {"arrows": "to", "color": "#97c2fc", "from": "NIPS 2017", "label": "HOSTED", "to": "31st Conference on Neural Information Processing Systems"}, {"arrows": "to", "color": "#97c2fc", "from": "self-attention layer", "label": "RELATED_TO", "to": "recurrent layer"}, {"arrows": "to", "color": "#97c2fc", "from": "self-attention layer", "label": "RELATED_TO", "to": "convolutional layer"}, {"arrows": "to", "color": "#97c2fc", "from": "self-attention layer", "label": "IMPROVES", "to": "computational performance"}, {"arrows": "to", "color": "#97c2fc", "from": "self-attention layer", "label": "ACHIEVES", "to": "interpretable models"}, {"arrows": "to", "color": "#97c2fc", "from": "self-attention layer", "label": "EXTENDS", "to": "restricted self-attention"}, {"arrows": "to", "color": "#97c2fc", "from": "self-attention layer", "label": "PART_OF", "to": "model"}, {"arrows": "to", "color": "#97c2fc", "from": "recurrent layer", "label": "RELATED_TO", "to": "convolutional layer"}, {"arrows": "to", "color": "#97c2fc", "from": "recurrent layer", "label": "DEPENDS_ON", "to": "sequential operations"}, {"arrows": "to", "color": "#97c2fc", "from": "convolutional layer", "label": "RELATED_TO", "to": "self-attention layer"}, {"arrows": "to", "color": "#97c2fc", "from": "convolutional layer", "label": "DEPENDS_ON", "to": "kernel width"}, {"arrows": "to", "color": "#97c2fc", "from": "convolutional layer", "label": "DEPENDS_ON", "to": "dilated convolutions"}, {"arrows": "to", "color": "#97c2fc", "from": "convolutional layer", "label": "DEPENDS_ON", "to": "Separable Convolutions"}, {"arrows": "to", "color": "#97c2fc", "from": "model", "label": "CONTAINS", "to": "self-attention layer"}, {"arrows": "to", "color": "#97c2fc", "from": "model", "label": "CONTAINS", "to": "Point-Wise Feed-Forward Layer"}, {"arrows": "to", "color": "#97c2fc", "from": "model", "label": "TRAINED_ON", "to": "WMT 2014 English-German dataset"}, {"arrows": "to", "color": "#97c2fc", "from": "model", "label": "TRAINED_ON", "to": "WMT 2014 English-French dataset"}, {"arrows": "to", "color": "#97c2fc", "from": "model", "label": "EVALUATES", "to": "sequence transduction tasks"}, {"arrows": "to", "color": "#97c2fc", "from": "position", "label": "DESCRIBED_IN", "to": "positional encoding"}, {"arrows": "to", "color": "#97c2fc", "from": "positional encoding", "label": "USES", "to": "sine and cosine functions"}, {"arrows": "to", "color": "#97c2fc", "from": "positional encoding", "label": "EXTENDS", "to": "learned positional embeddings"}, {"arrows": "to", "color": "#97c2fc", "from": "positional encoding", "label": "ACHIEVES", "to": "ability to extrapolate"}, {"arrows": "to", "color": "#97c2fc", "from": "attention distribution", "label": "ILLUSTRATES", "to": "syntactic and semantic structure"}, {"arrows": "to", "color": "#97c2fc", "from": "Multi-Head Attention", "label": "USES", "to": "model"}, {"arrows": "to", "color": "#97c2fc", "from": "single-head attention", "label": "COMPARED_TO", "to": "Multi-Head Attention"}, {"arrows": "to", "color": "#97c2fc", "from": "Multi-Head Attention", "label": "IMPLEMENTS", "to": "multi-head(Q, K, V ) = Concat(head 1, ..., headh)W O"}, {"arrows": "to", "color": "#97c2fc", "from": "Multi-Head Attention", "label": "USES", "to": "h = 8 parallel attention layers"}, {"arrows": "to", "color": "#97c2fc", "from": "Multi-Head Attention", "label": "USES", "to": "dk = dv = dmodel/h = 64"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "USES", "to": "Multi-Head Attention"}, {"arrows": "to", "color": "#97c2fc", "from": "encoder-decoder attention", "label": "USES", "to": "Multi-Head Attention"}, {"arrows": "to", "color": "#97c2fc", "from": "Encoder", "label": "CONTAINS", "to": "self-attention layers"}, {"arrows": "to", "color": "#97c2fc", "from": "self-attention layers", "label": "USES", "to": "all of the keys, values and queries come from the same place"}, {"arrows": "to", "color": "#97c2fc", "from": "Decoder", "label": "CONTAINS", "to": "self-attention layers"}, {"arrows": "to", "color": "#97c2fc", "from": "Position-wise Feed-Forward Networks", "label": "USES", "to": "fully connected feed-forward network"}, {"arrows": "to", "color": "#97c2fc", "from": "Position-wise Feed-Forward Networks", "label": "USES", "to": "two linear transformations with a ReLU activation in between"}, {"arrows": "to", "color": "#97c2fc", "from": "embeddings", "label": "USES", "to": "learned embeddings"}, {"arrows": "to", "color": "#97c2fc", "from": "embeddings", "label": "SHARES", "to": "weight matrix"}, {"arrows": "to", "color": "#97c2fc", "from": "Self-Attention", "label": "COMPARISON", "to": "recurrent and convolutional layers"}, {"arrows": "to", "color": "#97c2fc", "from": "Self-Attention", "label": "ACHIEVES", "to": "learning long-range dependencies"}, {"arrows": "to", "color": "#97c2fc", "from": "positional encodings", "label": "USES", "to": "sine and cosine functions of different frequencies"}, {"arrows": "to", "color": "#97c2fc", "from": "positional encodings", "label": "USES", "to": "positional encodings have the same dimension dmodel as the embeddings"}, {"arrows": "to", "color": "#97c2fc", "from": "Recurrent Neural Network", "label": "RELATED_TO", "to": "Sequence Modeling"}, {"arrows": "to", "color": "#97c2fc", "from": "Recurrent Neural Network", "label": "RELATED_TO", "to": "Machine Translation"}, {"arrows": "to", "color": "#97c2fc", "from": "Recurrent Neural Network", "label": "RELATED_TO", "to": "Language Modeling"}, {"arrows": "to", "color": "#97c2fc", "from": "Recurrent Neural Network", "label": "RELATED_TO", "to": "Encoder-Decoder Architecture"}, {"arrows": "to", "color": "#97c2fc", "from": "Recurrent Neural Network", "label": "RELATED_TO", "to": "Recurrent Attention Mechanism"}, {"arrows": "to", "color": "#97c2fc", "from": "Recurrent Neural Network", "label": "RELATED_TO", "to": "Sequence-Aligned Recurrence"}, {"arrows": "to", "color": "#97c2fc", "from": "Long Short-Term Memory", "label": "RELATED_TO", "to": "Sequence Modeling"}, {"arrows": "to", "color": "#97c2fc", "from": "Long Short-Term Memory", "label": "RELATED_TO", "to": "Machine Translation"}, {"arrows": "to", "color": "#97c2fc", "from": "Long Short-Term Memory", "label": "RELATED_TO", "to": "Language Modeling"}, {"arrows": "to", "color": "#97c2fc", "from": "Gated Recurrent Neural Network", "label": "RELATED_TO", "to": "Sequence Modeling"}, {"arrows": "to", "color": "#97c2fc", "from": "Gated Recurrent Neural Network", "label": "RELATED_TO", "to": "Machine Translation"}, {"arrows": "to", "color": "#97c2fc", "from": "Gated Recurrent Neural Network", "label": "RELATED_TO", "to": "Language Modeling"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "RELATED_TO", "to": "Sequence Modeling"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "RELATED_TO", "to": "Language Modeling"}, {"arrows": "to", "color": "#97c2fc", "from": "Extended Neural GPU", "label": "RELATED_TO", "to": "Sequence Modeling"}, {"arrows": "to", "color": "#97c2fc", "from": "Extended Neural GPU", "label": "RELATED_TO", "to": "Machine Translation"}, {"arrows": "to", "color": "#97c2fc", "from": "Extended Neural GPU", "label": "RELATED_TO", "to": "Language Modeling"}, {"arrows": "to", "color": "#97c2fc", "from": "ByteNet", "label": "RELATED_TO", "to": "Sequence Modeling"}, {"arrows": "to", "color": "#97c2fc", "from": "ByteNet", "label": "RELATED_TO", "to": "Machine Translation"}, {"arrows": "to", "color": "#97c2fc", "from": "ByteNet", "label": "RELATED_TO", "to": "Language Modeling"}, {"arrows": "to", "color": "#97c2fc", "from": "Scaled Dot-Product Attention", "label": "RELATED_TO", "to": "Multi-Head Attention"}, {"arrows": "to", "color": "#97c2fc", "from": "Multi-Head Attention", "label": "USES", "to": "attention layers"}, {"arrows": "to", "color": "#97c2fc", "from": "Multi-Head Attention", "label": "CONTAINS", "to": "Attention Function"}, {"arrows": "to", "color": "#97c2fc", "from": "Multi-Head Attention", "label": "ACHIEVES", "to": "jointly attend to information from different representation subspaces at different positions"}, {"arrows": "to", "color": "#97c2fc", "from": "Multi-Head Attention", "label": "USES", "to": "parallel attention layers"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "CONTAINS", "to": "encoder-decoder attention layers"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "CONTAINS", "to": "self-attention layers"}, {"arrows": "to", "color": "#97c2fc", "from": "Position-wise Feed-Forward Networks", "label": "CONTAINS", "to": "fully connected feed-forward network"}, {"arrows": "to", "color": "#97c2fc", "from": "Position-wise Feed-Forward Networks", "label": "USES", "to": "linear transformations"}, {"arrows": "to", "color": "#97c2fc", "from": "Embeddings and Softmax", "label": "USES", "to": "learned embeddings"}, {"arrows": "to", "color": "#97c2fc", "from": "Embeddings and Softmax", "label": "USES", "to": "Softmax Function"}, {"arrows": "to", "color": "#97c2fc", "from": "Scaled Dot-Product Attention", "label": "COMPARSED_TO", "to": "Additive Attention"}, {"arrows": "to", "color": "#97c2fc", "from": "Scaled Dot-Product Attention", "label": "COMPARSED_TO", "to": "Dot-Product Attention"}, {"arrows": "to", "color": "#97c2fc", "from": "Scaled Dot-Product Attention", "label": "IMPROVES", "to": "dot-product attention without scaling"}, {"arrows": "to", "color": "#97c2fc", "from": "Scaled Dot-Product Attention", "label": "DEPENDS_ON", "to": "scaling factor"}, {"arrows": "to", "color": "#97c2fc", "from": "Multi-Head Attention", "label": "DEPENDS_ON", "to": "linear projections"}, {"arrows": "to", "color": "#97c2fc", "from": "Multi-Head Attention", "label": "EXTENDS", "to": "single-head attention"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "DEPENDS_ON", "to": "Multi-Head Attention"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "DEPENDS_ON", "to": "encoder-decoder attention layers"}, {"arrows": "to", "color": "#97c2fc", "from": "Transformer Architecture", "label": "DEPENDS_ON", "to": "self-attention layers"}]);

                  nodeColors = {};
                  allNodes = nodes.get({ returnType: "Object" });
                  for (nodeId in allNodes) {
                    nodeColors[nodeId] = allNodes[nodeId].color;
                  }
                  allEdges = edges.get({ returnType: "Object" });
                  // adding nodes and edges to the graph
                  data = {nodes: nodes, edges: edges};

                  var options = {"physics": {"forceAtlas2Based": {"gravitationalConstant": -50, "centralGravity": 0.01, "springLength": 110, "springConstant": 0.08}, "maxVelocity": 50, "solver": "forceAtlas2Based", "timestep": 0.35, "stabilization": {"enabled": true, "iterations": 900}}, "interaction": {"navigationButtons": true, "keyboard": true, "hover": true, "zoomView": true}};

                  


                  

                  network = new vis.Network(container, data, options);

                  

                  

                  


                  
                      network.on("stabilizationProgress", function(params) {
                          document.getElementById('loadingBar').removeAttribute("style");
                          var maxWidth = 496;
                          var minWidth = 20;
                          var widthFactor = params.iterations/params.total;
                          var width = Math.max(minWidth,maxWidth * widthFactor);
                          document.getElementById('bar').style.width = width + 'px';
                          document.getElementById('text').innerHTML = Math.round(widthFactor*100) + '%';
                      });
                      network.once("stabilizationIterationsDone", function() {
                          document.getElementById('text').innerHTML = '100%';
                          document.getElementById('bar').style.width = '496px';
                          document.getElementById('loadingBar').style.opacity = 0;
                          // really clean the dom element
                          setTimeout(function () {document.getElementById('loadingBar').style.display = 'none';}, 500);
                      });
                  

                  return network;

              }
              drawGraph();
        </script>
    </body>
</html>